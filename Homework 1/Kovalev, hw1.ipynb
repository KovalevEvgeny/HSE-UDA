{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 1. NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работу выполнил Ковалев Евгений, студент 4 курса бакалавриата факультета математики НИУ ВШЭ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном домашнем задании необходимо было попрактиковаться в работе с NLTK. Из данного текста нужно было выделить наиболее часто встречающиеся словоформы и леммы со стоп-словами и без, найти более-менее осмысленные синонимы и слова с общим контекстом, а также придумать пример на задачу лемматизации, где pymorphy показывает себя лучше mystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk import FreqDist, Text, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "stop_words = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Выберите произвольный достаточно длинный текст.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения задания был выбран текст романа Джерома Сэлинджера «Над пропастью во ржи», доступный по данной ссылке: https://www.e-reading.club/bookreader.php/55486/Selindzher_-_Nad_propast%27yu_vo_rzhi.html\n",
    "\n",
    "Посмотрим, насколько он велик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = ''\n",
    "with open('the_catcher_in_the_rye_rus.txt') as file:\n",
    "    for line in file:\n",
    "        text += line.strip() + ' '\n",
    "text = text.replace('— ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    tokens = WhitespaceTokenizer().tokenize(text.lower())\n",
    "    types = FreqDist(tokens)\n",
    "    return tokens, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens: 56868\n",
      "number of types: 13890\n"
     ]
    }
   ],
   "source": [
    "text_tokens, text_types = tokenization(text)\n",
    "print('number of tokens:', len(text_tokens))\n",
    "print('number of types:', len(text_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, выбранный текст содержит почти 57 тысяч токенов и почти 14 тысяч типов, так что его можно считать достаточно большим и подходящим для анализа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Найдите 20 самых частотных словоформ и лемм со стоп-словами и без стоп-слов.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Словоформы со стоп-словами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 9637 samples and 56874 outcomes>\n",
      "[('я', 2114), ('не', 1758), ('и', 1699), ('в', 1284), ('что', 1073), ('он', 871), ('на', 775), ('а', 695), ('но', 636), ('она', 581), ('с', 558), ('у', 514), ('все', 503), ('как', 502), ('меня', 478), ('мне', 476), ('было', 392), ('это', 353), ('ты', 349), ('когда', 322)]\n"
     ]
    }
   ],
   "source": [
    "prog = re.compile('[А-Яа-я\\-]+')\n",
    "l1 = prog.findall(text.lower())\n",
    "d1 = FreqDist(l1)\n",
    "print(d1)\n",
    "print(d1.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Словоформы без стоп-слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 9487 samples and 29977 outcomes>\n",
      "[('это', 353), ('говорю', 204), ('очень', 197), ('сказал', 174), ('говорит', 166), ('просто', 128), ('тебе', 124), ('наверно', 114), ('знаю', 112), ('ужасно', 107), ('стал', 95), ('время', 93), ('фиби', 91), ('вообще', 83), ('равно', 77), ('мог', 73), ('хотелось', 73), ('сразу', 70), ('все-таки', 68), ('слово', 68)]\n"
     ]
    }
   ],
   "source": [
    "l2 = [w for w in l1 if not w in stop_words]\n",
    "d2 = FreqDist(l2)\n",
    "print(d2)\n",
    "print(d2.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Леммы со стоп-словами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 5270 samples and 56874 outcomes>\n",
      "[('я', 3126), ('не', 1758), ('и', 1699), ('он', 1452), ('в', 1341), ('что', 1127), ('она', 1038), ('быть', 980), ('на', 775), ('а', 695), ('весь', 682), ('с', 640), ('но', 636), ('ты', 625), ('у', 514), ('говорить', 507), ('как', 502), ('это', 494), ('они', 430), ('сказать', 334)]\n"
     ]
    }
   ],
   "source": [
    "morph = MorphAnalyzer()\n",
    "l3 = [morph.parse(token)[0].normal_form for token in l1]\n",
    "d3 = FreqDist(l3)\n",
    "print(d3)\n",
    "print(d3.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Леммы без стоп-слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 5165 samples and 30139 outcomes>\n",
      "[('весь', 682), ('говорить', 507), ('это', 494), ('сказать', 334), ('мочь', 271), ('знать', 243), ('очень', 197), ('стать', 188), ('ещё', 176), ('свой', 160), ('ничто', 159), ('хотеть', 137), ('который', 136), ('самый', 134), ('просто', 128), ('слово', 122), ('идти', 122), ('понимать', 121), ('наверно', 114), ('спрашивать', 112)]\n"
     ]
    }
   ],
   "source": [
    "l4 = [w for w in l3 if not w in stop_words]\n",
    "d4 = FreqDist(l4)\n",
    "print(d4)\n",
    "print(d4.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что стоп-слова сильно засоряют список наиболее часто встречающихся словоформ и лемм, и при их отбрасывании картина становится менее бессмысленной. Например, в случае словоформ в списке топ-20 частотных появляется словоформа \"фиби\", которая на самом деле является именем главной героини романа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Найдите пример, в котором pymorphy «выиграет» у mystem.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При решении данного пункта возникло предположение, что mystem работает намного лучше, чем pymorphy, ибо пример упорно не находился: mystem все время опережал pymorphy в качестве. Однако мои попытки все же увенчались успехом, и я обнаружил, что mystem не идеально справляется с выбором правильного вида (совершенного или несовершенного) глагола. Мой пример — фраза из трека Oxxxymiron — «Накануне»:\n",
    "\n",
    "«Доигрался ты, старый дурак, вот и вся эпитафия» "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pymorphy: доиграться ты старый дурак вот и весь эпитафия\n",
      "mystem: доигрываться ты старый дурак вот и весь эпитафия\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = 'доигрался ты старый дурак вот и вся эпитафия'\n",
    "morph_lemmas = [morph.parse(w)[0].normal_form for w in example.split()]\n",
    "mystem_lemmas = mystem.lemmatize(example)\n",
    "print('pymorphy:', ' '.join(morph_lemmas))\n",
    "print('mystem:', ''.join(mystem_lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате обработки данной цитаты двумя лемматизаторами видно, что pymorphy справился лучше — в данном контексте глагол «доиграться» совершенного вида лучше передает смысл предложения, чем глагол «доигрываться» несовершенного вида."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Найдите осмысленные синонимы в тексте, а также слова с общим контекстом.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: 1 Если вам на самом деле хочется услышать...>\n"
     ]
    }
   ],
   "source": [
    "nltk_text = Text(word_tokenize(text))\n",
    "print(nltk_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более-менее осмысленные синонимы:\n",
    "\n",
    "«вам» и «тебе»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тебе мне ей ничего и она уже бы ему он ее сразу ты тебя вы я не говорю\n",
      "это почти\n"
     ]
    }
   ],
   "source": [
    "nltk_text.similar('вам')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "«ничуть» и «ничего»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ничего и даже уже никогда вовсе совершенно никак чуть почти совсем все\n",
      "его конечно вам я мне бы этого меня\n"
     ]
    }
   ],
   "source": [
    "nltk_text.similar('ничуть')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "«голливуд» и «кино»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кино пэнси субботу общем лифчик истории шкаф восторге пижамах носу\n",
      "столовую году капелле комнату гости зеркало отпуск мейне семье гольф\n"
     ]
    }
   ],
   "source": [
    "nltk_text.similar('голливуд')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слова с общим контекстом:\n",
    "\n",
    "«он» и «она»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "что_уже а_и что_меня вдруг_меня равно_бы что_действительно что_просто\n",
      "но_все но_всегда тут_вдруг что_не что_даже а_говорит что_тебе но_мне\n",
      "но_не и_вдруг и_не а_не что_ужасно\n"
     ]
    }
   ],
   "source": [
    "nltk_text.common_contexts(['он', 'она'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "«сказал» и «говорю»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "не_но галлахер_я и_что я_нет я_в да_и\n"
     ]
    }
   ],
   "source": [
    "nltk_text.common_contexts(['сказал', 'говорю'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "«очень» и «слишком»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сейчас_поздно уж_не\n"
     ]
    }
   ],
   "source": [
    "nltk_text.common_contexts(['очень', 'слишком'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
