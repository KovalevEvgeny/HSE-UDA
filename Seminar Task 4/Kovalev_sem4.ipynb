{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном задании нужно было попрактиковаться в работе с синтаксическим парсером SyntaxNet и в извлечении SVO-троек из предложений. Необходимо было улучшить простейший код, извлекающий SVO-тройки, чтобы они были полными, чтобы учитывался порядок слов в предложении и однородные члены, после чего придумать собственные примеры и протестировать его на них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import DependencyGraph\n",
    "import codecs\n",
    "\n",
    "def svo(file, tree=False):\n",
    "    processed_sentences = []\n",
    "    sentence = []\n",
    "    for line in codecs.open(file, 'r', 'utf-8'):\n",
    "        if len(line) == 1:\n",
    "            processed_sentences.append(sentence)\n",
    "            sentence = []\n",
    "        else:\n",
    "            word = line.split(\"\\t\")\n",
    "            sentence.append(word)\n",
    "    \n",
    "    deps = []\n",
    "    for sentence in processed_sentences:\n",
    "        s = u''\n",
    "        for line in sentence:\n",
    "            s += u\"\\t\".join(line) + u'\\n'\n",
    "        deps.append(s)\n",
    "    \n",
    "    if tree:\n",
    "        for sent_dep in deps:\n",
    "            # борьба с кодировкой\n",
    "            sent_dep = sent_dep.replace('\\ufeff', '')\n",
    "            graph = DependencyGraph(tree_str=sent_dep)\n",
    "            for triple in graph.triples():\n",
    "                for elem in triple:\n",
    "                    print (elem[0] if isinstance(elem, tuple) else elem,)\n",
    "                print()\n",
    "            print()\n",
    "            print(graph.tree().pretty_print())\n",
    "\n",
    "    for sent_dep in deps:\n",
    "        # борьба с кодировкой\n",
    "        sent_dep = sent_dep.replace('\\ufeff', '')\n",
    "        verbs = {}\n",
    "        for t in sent_dep.split('\\n'):\n",
    "            if len(t) > 1:\n",
    "                splt = t.split('\\t')\n",
    "                if splt[3] == 'VERB':\n",
    "                    # вместе с глаголом сохраним словарь, в который будем добавлять слова с соответствующими связями с ним\n",
    "                    verbs[splt[0]] = (splt[1], {'nsubj': [], 'dobj': []})\n",
    "\n",
    "        for t in sent_dep.split('\\n'):\n",
    "            if len(t) > 1:\n",
    "                splt = t.split('\\t')\n",
    "                if splt[7] in ['nsubj', 'dobj']:\n",
    "                    if splt[6] in verbs:\n",
    "                        # на основании связи с глаголом добавляем слово в словарь, сохраняя при этом его номер, чтобы учесть порядок\n",
    "                        verbs[splt[6]][1][splt[7]].append((splt[1], splt[0]))\n",
    "\n",
    "        # проходим по сохраненным номерам, обозначающим положение глагола в предложении\n",
    "        for index in verbs.keys():\n",
    "            # выделяем глагол\n",
    "            verb = verbs[index][0]\n",
    "            # выделяем все слова, имеющие связи nsubj и dobj с рассматриваемым глаголом\n",
    "            nsubj = verbs[index][1]['nsubj']\n",
    "            dobj = verbs[index][1]['dobj']\n",
    "            # проверяем, что SVO-тройка полна\n",
    "            if nsubj and dobj:\n",
    "                # массив из троек (слово, связанное с глаголом связью nsubj; глагол; слово, связанное с глаголом связью dobj)\n",
    "                triples = []\n",
    "                # перечисляем все возможные тройки\n",
    "                for nsubj_word in nsubj:\n",
    "                    for dobj_word in dobj:\n",
    "                        # добавляем тройку в массив из троек\n",
    "                        triples.append((nsubj_word, (verb, index), dobj_word))\n",
    "                # сортируем слова по положению в соответствующем предложении, чтобы сохранить порядок, и выводим\n",
    "                for tr in triples:\n",
    "                    print([a for (a, b) in sorted(tr, key=lambda x: x[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Совет', 'продлил', 'санкции']\n",
      "['Радикалы', 'зажгли', 'файеры']\n"
     ]
    }
   ],
   "source": [
    "svo('data.conll')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, на исходном примере все работает, как нужно. Рассмотрим следующие предложения:\n",
    "\n",
    "> Я купил яблоки и бананы .\n",
    "\n",
    "> Сумку и куртку ты оставил в коридоре .\n",
    "\n",
    "> Утюгом я глажу бельё .\n",
    "\n",
    "> Шлю я тебе большой привет и поцелуй .\n",
    "\n",
    "Извлечены должны быть следующие SVO:\n",
    "\n",
    "> Я купил яблоки, я купил бананы, Cумку ты оставил, куртку ты оставил, Утюгом я глажу, я глажу бельё, Шлю я тебе, Шлю я привет, Шлю я поцелуй"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Я', 'купил', 'яблоки']\n",
      "['Сумку', 'ты', 'оставил']\n",
      "['я', 'глажу', 'бельё']\n",
      "['Шлю', 'я', 'привет']\n"
     ]
    }
   ],
   "source": [
    "svo('data2.conll')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В чем же проблема?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "купил\n",
      "nsubj\n",
      "Я\n",
      "\n",
      "купил\n",
      "dobj\n",
      "яблоки\n",
      "\n",
      "купил\n",
      "cc\n",
      "и\n",
      "\n",
      "купил\n",
      "conj\n",
      "бананы\n",
      "\n",
      "купил\n",
      "punct\n",
      ".\n",
      "\n",
      "\n",
      "           купил           \n",
      "  ___________|___________   \n",
      " Я  яблоки   и   бананы  . \n",
      "\n",
      "None\n",
      "оставил\n",
      "dobj\n",
      "Сумку\n",
      "\n",
      "Сумку\n",
      "cc\n",
      "и\n",
      "\n",
      "Сумку\n",
      "conj\n",
      "куртку\n",
      "\n",
      "оставил\n",
      "nsubj\n",
      "ты\n",
      "\n",
      "оставил\n",
      "nmod\n",
      "коридоре\n",
      "\n",
      "коридоре\n",
      "case\n",
      "в\n",
      "\n",
      "оставил\n",
      "punct\n",
      ".\n",
      "\n",
      "\n",
      "        оставил                      \n",
      "  _________|____________________      \n",
      " |   |          Сумку        коридоре\n",
      " |   |      ______|_____        |     \n",
      " ты  .     и          куртку    в    \n",
      "\n",
      "None\n",
      "глажу\n",
      "nmod\n",
      "Утюгом\n",
      "\n",
      "глажу\n",
      "nsubj\n",
      "я\n",
      "\n",
      "глажу\n",
      "dobj\n",
      "бельё\n",
      "\n",
      "глажу\n",
      "punct\n",
      ".\n",
      "\n",
      "\n",
      "       глажу          \n",
      "   ______|__________   \n",
      "Утюгом   я   бельё  . \n",
      "\n",
      "None\n",
      "Шлю\n",
      "nsubj\n",
      "я\n",
      "\n",
      "Шлю\n",
      "nmod\n",
      "тебе\n",
      "\n",
      "Шлю\n",
      "dobj\n",
      "привет\n",
      "\n",
      "привет\n",
      "amod\n",
      "большой\n",
      "\n",
      "привет\n",
      "cc\n",
      "и\n",
      "\n",
      "привет\n",
      "conj\n",
      "поцелуй\n",
      "\n",
      "Шлю\n",
      "punct\n",
      ".\n",
      "\n",
      "\n",
      "         Шлю                       \n",
      "  ________|____________             \n",
      " |   |    |          привет        \n",
      " |   |    |      ______|_______     \n",
      " я  тебе  .  большой   и    поцелуй\n",
      "\n",
      "None\n",
      "['Я', 'купил', 'яблоки']\n",
      "['Сумку', 'ты', 'оставил']\n",
      "['я', 'глажу', 'бельё']\n",
      "['Шлю', 'я', 'привет']\n"
     ]
    }
   ],
   "source": [
    "svo('data2.conll', tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1\\tЯ\\t_\\tPRON\\t_\\tfPOS=PRON++\\t2\\tnsubj\\t_\\t_',\n",
       " '',\n",
       " '2\\tкупил\\t_\\tVERB\\t_\\tAspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act|fPOS=VERB++\\t0\\tROOT\\t_\\t_',\n",
       " '',\n",
       " '3\\tяблоки\\t_\\tNOUN\\t_\\tAnimacy=Inan|Case=Acc|Gender=Masc|Number=Plur|fPOS=NOUN++\\t2\\tdobj\\t_\\t_',\n",
       " '',\n",
       " '4\\tи\\t_\\tCONJ\\t_\\tfPOS=CONJ++\\t2\\tcc\\t_\\t_',\n",
       " '',\n",
       " '5\\tбананы\\t_\\tVERB\\t_\\tAnimacy=Inan|Case=Acc|Gender=Fem|Number=Plur|fPOS=NOUN++\\t2\\tconj\\t_\\t_',\n",
       " '',\n",
       " '6\\t.\\t_\\tPUNCT\\t.\\tfPOS=PUNCT++.\\t2\\tpunct\\t_\\t_',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_sentences = []\n",
    "sentence = []\n",
    "for line in codecs.open('data2.conll', 'r', 'utf-8'):\n",
    "    if len(line) == 1:\n",
    "        processed_sentences.append(sentence)\n",
    "        sentence = []\n",
    "    else:\n",
    "        word = line.split(\"\\t\")\n",
    "        sentence.append(word)\n",
    "\n",
    "deps = []\n",
    "for sentence in processed_sentences:\n",
    "    s = u''\n",
    "    for line in sentence:\n",
    "        s += u\"\\t\".join(line) + u'\\n'\n",
    "    deps.append(s)\n",
    "    \n",
    "deps[0].split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, \"бананы\" - это, оказывается, глагол!\n",
    "\n",
    "Видно, что в некоторых местах парсер выдал абсурдный результат. В таком случае логично немного отредактировать файл 'data2.conll', чтобы избавиться от самого бреда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Я', 'купил', 'яблоки']\n",
      "['Я', 'купил', 'бананы']\n",
      "['Сумку', 'ты', 'оставил']\n",
      "['куртку', 'ты', 'оставил']\n",
      "['Утюгом', 'я', 'глажу']\n",
      "['я', 'глажу', 'бельё']\n",
      "['Шлю', 'я', 'тебе']\n",
      "['Шлю', 'я', 'привет']\n",
      "['Шлю', 'я', 'поцелуй']\n"
     ]
    }
   ],
   "source": [
    "svo('data2_1.conll')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так-то лучше."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
