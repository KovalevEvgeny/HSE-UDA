{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tproger.ru/translations/markov-chains/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Цепи Маркова для автоматической генерации тектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Структура данных Dictogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictogram (dict — встроенный тип данных словарь в Python) будет отображать зависимость между звеньями и их частотой появления в тексте, то есть их распределение. Но при этом она будет обладать нужным нам свойством словаря — время выполнения программы не будет зависеть от объема входных данных, а это значит, мы создаем эффективный алгоритм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Dictogram(dict):\n",
    "    def __init__(self, iterable=None):\n",
    "        # Инициализируем наше распределение как новый объект класса, \n",
    "        # добавляем имеющиеся элементы\n",
    "        super(Dictogram, self).__init__()\n",
    "        self.types = 0  # число уникальных ключей в распределении\n",
    "        self.tokens = 0  # общее количество всех слов в распределении\n",
    "        if iterable:\n",
    "            self.update(iterable)\n",
    "\n",
    "    def update(self, iterable):\n",
    "        # Обновляем распределение элементами из имеющегося \n",
    "        # итерируемого набора данных\n",
    "        for item in iterable:\n",
    "            if item in self:\n",
    "                self[item] += 1\n",
    "                self.tokens += 1\n",
    "            else:\n",
    "                self[item] = 1\n",
    "                self.types += 1\n",
    "                self.tokens += 1\n",
    "\n",
    "    def count(self, item):\n",
    "        # Возвращаем значение счетчика элемента, или 0\n",
    "        if item in self:\n",
    "            return self[item]\n",
    "        return 0\n",
    "\n",
    "    def return_random_word(self):\n",
    "        random_key = random.sample(self, 1)\n",
    "        # Другой способ:\n",
    "        # random.choice(histogram.keys())\n",
    "        return random_key[0]\n",
    "\n",
    "    def return_weighted_random_word(self):\n",
    "        # Сгенерировать псевдослучайное число между 0 и (n-1),\n",
    "        # где n - общее число слов\n",
    "        random_int = random.randint(0, self.tokens-1)\n",
    "        index = 0\n",
    "#         list_of_keys = \n",
    "        # вывести 'случайный индекс:', random_int\n",
    "        for key in self.keys():\n",
    "            index += self[key]\n",
    "            # вывести индекс\n",
    "            if(index > random_int):\n",
    "                # вывести list_of_keys[i]\n",
    "                return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В конструктор структуре Dictogram можно передать любой объект, по которому можно итерироваться. Элементами этого объекта будут слова для инициализации Dictogram, например, все слова из какой-нибудь книги. В данном случае мы ведем подсчет элементов, чтобы для обращения к какому-либо из них не нужно было пробегать каждый раз по всему набору данных.\n",
    "\n",
    "Мы также сделали две функции для возврата случайного слова. Одна функция выбирает случайный ключ в словаре, а другая, принимая во внимание число появлений каждого слова в тексте, возвращает нужное нам слово."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Структура цепи Маркова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_markov_model(data):\n",
    "    markov_model = dict()\n",
    "\n",
    "    for i in range(0, len(data)-1):\n",
    "        if data[i] in markov_model:\n",
    "            # Просто присоединяем к уже существующему распределению\n",
    "            markov_model[data[i]].update([data[i+1]])\n",
    "        else:\n",
    "            markov_model[data[i]] = Dictogram([data[i+1]])\n",
    "    return markov_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В реализации выше у нас есть словарь, который хранит окна в качестве ключа в паре «(ключ, значение)» и распределения в качестве значений в этой паре."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cтруктура цепи Маркова N-го порядка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_higher_order_markov_model(order, data):\n",
    "    markov_model = dict()\n",
    "\n",
    "    for i in range(0, len(data)-order):\n",
    "        # Создаем окно\n",
    "        window = tuple(data[i: i+order])\n",
    "        # Добавляем в словарь\n",
    "        if window in markov_model:\n",
    "            # Присоединяем к уже существующему распределению\n",
    "            markov_model[window].update([data[i+order]])\n",
    "        else:\n",
    "            markov_model[window] = Dictogram([data[i+order]])\n",
    "    return markov_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Парсинг модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, мы реализовали словарь. Но как теперь совершить генерацию контента, основываясь на текущем состоянии и шаге к следующему состоянию? Пройдемся по нашей модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import re\n",
    "\n",
    "\n",
    "def generate_random_start(model):\n",
    "    # Чтобы сгенерировать любое начальное слово, раскомментируйте строку:\n",
    "    # return random.choice(model.keys())\n",
    "\n",
    "    # Чтобы сгенерировать \"правильное\" начальное слово, используйте код ниже:\n",
    "    # Правильные начальные слова - это те, что являлись началом предложений в корпусе\n",
    "    if 'END' in model:\n",
    "        seed_word = 'END'\n",
    "        while seed_word == 'END':\n",
    "            seed_word = model['END'].return_weighted_random_word()\n",
    "        return seed_word\n",
    "    return random.choice(list(model.keys()))\n",
    "\n",
    "\n",
    "def generate_random_sentence(length, markov_model):\n",
    "    current_word = generate_random_start(markov_model)\n",
    "    sentence = [current_word]\n",
    "    for i in range(0, length):\n",
    "        current_dictogram = markov_model[current_word]\n",
    "        random_weighted_word = current_dictogram.return_weighted_random_word()\n",
    "        current_word = random_weighted_word\n",
    "        sentence.append(current_word)\n",
    "    sentence[0] = sentence[0].capitalize()\n",
    "    return ' '.join(sentence) + '.'\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше генерировать «правильные» начальные слова – те, которые и в исходном тексте стояли в начале предложения. Для этого мы в словаре находим все ключи «END» и выбираем слово, следующее за одним из них. После генерации начального слова мы ищем, какое слово может идти дальше, обращаясь к тому же словарю, и выбираем нужное на основании комбинации вероятности и случайности. Продолжаем это делать, пока предложение не достигнет установленной нами длины, и в конце возвращаем его. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['today', 'you', 'are', 'you', 'END', 'that', 'is', 'truer', 'than', 'true', 'END', 'there', 'is', 'no', 'one', 'alive', 'who', 'is', 'you-er', 'than', 'you', 'END', 'you', 'have', 'brains', 'in', 'your', 'head', 'END', 'you', 'have', 'feet', 'in', 'your', 'shoes', 'END', 'you', 'can', 'steer', 'yourself', 'any', 'direction', 'you', 'choose', 'END', 'you’re', 'on', 'your', 'own', 'END', 'the', 'more', 'that', 'you', 'read', 'the', 'more', 'things', 'you', 'will', 'know', 'END', 'the', 'more', 'that', 'you', 'learn', 'the', 'more', 'places', 'you’ll', 'go', 'END', 'think', 'left', 'and', 'think', 'right', 'and', 'think', 'low', 'and', 'think', 'high', 'END', 'oh', 'the', 'thinks', 'you', 'can', 'think', 'up', 'if', 'only', 'you', 'try', 'END']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Today you are you. That is truer than true. There is no one\n",
    "alive who is you-er than you»\n",
    "«You have brains in your head. You have feet in your shoes.\n",
    "You can steer yourself any direction you choose. You’re on\n",
    "your own»\n",
    "«The more that you read, the more things you will know. The\n",
    "more that you learn, the more places you’ll go»\n",
    "«Think left and think right and think low and think high. Oh,\n",
    "the thinks you can think up if only you try»\"\"\"\n",
    "\n",
    "# text = open('oldman.txt', 'r').read()\n",
    "text = text.replace(\"»\", \" END\").replace(\"«\", \"\").replace(\"\\n\", \" \").replace(\".\", \" END\").replace(\",\", \"\")\n",
    "frags = [f.lower() if f != 'END' else f for f in text.split(\" \") if f]\n",
    "print(frags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для 1-го порядка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'END': {'oh': 1,\n",
       "  'that': 1,\n",
       "  'the': 2,\n",
       "  'there': 1,\n",
       "  'think': 1,\n",
       "  'you': 3,\n",
       "  'you’re': 1},\n",
       " 'alive': {'who': 1},\n",
       " 'and': {'think': 3},\n",
       " 'any': {'direction': 1},\n",
       " 'are': {'you': 1},\n",
       " 'brains': {'in': 1},\n",
       " 'can': {'steer': 1, 'think': 1},\n",
       " 'choose': {'END': 1},\n",
       " 'direction': {'you': 1},\n",
       " 'feet': {'in': 1},\n",
       " 'go': {'END': 1},\n",
       " 'have': {'brains': 1, 'feet': 1},\n",
       " 'head': {'END': 1},\n",
       " 'high': {'END': 1},\n",
       " 'if': {'only': 1},\n",
       " 'in': {'your': 2},\n",
       " 'is': {'no': 1, 'truer': 1, 'you-er': 1},\n",
       " 'know': {'END': 1},\n",
       " 'learn': {'the': 1},\n",
       " 'left': {'and': 1},\n",
       " 'low': {'and': 1},\n",
       " 'more': {'places': 1, 'that': 2, 'things': 1},\n",
       " 'no': {'one': 1},\n",
       " 'oh': {'the': 1},\n",
       " 'on': {'your': 1},\n",
       " 'one': {'alive': 1},\n",
       " 'only': {'you': 1},\n",
       " 'own': {'END': 1},\n",
       " 'places': {'you’ll': 1},\n",
       " 'read': {'the': 1},\n",
       " 'right': {'and': 1},\n",
       " 'shoes': {'END': 1},\n",
       " 'steer': {'yourself': 1},\n",
       " 'than': {'true': 1, 'you': 1},\n",
       " 'that': {'is': 1, 'you': 2},\n",
       " 'the': {'more': 4, 'thinks': 1},\n",
       " 'there': {'is': 1},\n",
       " 'things': {'you': 1},\n",
       " 'think': {'high': 1, 'left': 1, 'low': 1, 'right': 1, 'up': 1},\n",
       " 'thinks': {'you': 1},\n",
       " 'today': {'you': 1},\n",
       " 'true': {'END': 1},\n",
       " 'truer': {'than': 1},\n",
       " 'try': {'END': 1},\n",
       " 'up': {'if': 1},\n",
       " 'who': {'is': 1},\n",
       " 'will': {'know': 1},\n",
       " 'you': {'END': 2,\n",
       "  'are': 1,\n",
       "  'can': 2,\n",
       "  'choose': 1,\n",
       "  'have': 2,\n",
       "  'learn': 1,\n",
       "  'read': 1,\n",
       "  'try': 1,\n",
       "  'will': 1},\n",
       " 'you-er': {'than': 1},\n",
       " 'your': {'head': 1, 'own': 1, 'shoes': 1},\n",
       " 'yourself': {'any': 1},\n",
       " 'you’ll': {'go': 1},\n",
       " 'you’re': {'on': 1}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_markov_model(frags)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is you-er than true. you’re on your shoes. you learn the thinks you can think right and think right and think low and think high. you learn the more that is truer than you. you’re on your head. think low and think left and think high. you. there is no one alive who is truer than true. think right and think up if only you choose. you have brains in your shoes. there is you-er than true. there is you-er than true. that you try. you can.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_sentence(100, model).replace(\" END\", \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для N-го порядка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('END', 'oh'): {'the': 1},\n",
       " ('END', 'that'): {'is': 1},\n",
       " ('END', 'the'): {'more': 2},\n",
       " ('END', 'there'): {'is': 1},\n",
       " ('END', 'think'): {'left': 1},\n",
       " ('END', 'you'): {'can': 1, 'have': 2},\n",
       " ('END', 'you’re'): {'on': 1},\n",
       " ('alive', 'who'): {'is': 1},\n",
       " ('and', 'think'): {'high': 1, 'low': 1, 'right': 1},\n",
       " ('any', 'direction'): {'you': 1},\n",
       " ('are', 'you'): {'END': 1},\n",
       " ('brains', 'in'): {'your': 1},\n",
       " ('can', 'steer'): {'yourself': 1},\n",
       " ('can', 'think'): {'up': 1},\n",
       " ('choose', 'END'): {'you’re': 1},\n",
       " ('direction', 'you'): {'choose': 1},\n",
       " ('feet', 'in'): {'your': 1},\n",
       " ('go', 'END'): {'think': 1},\n",
       " ('have', 'brains'): {'in': 1},\n",
       " ('have', 'feet'): {'in': 1},\n",
       " ('head', 'END'): {'you': 1},\n",
       " ('high', 'END'): {'oh': 1},\n",
       " ('if', 'only'): {'you': 1},\n",
       " ('in', 'your'): {'head': 1, 'shoes': 1},\n",
       " ('is', 'no'): {'one': 1},\n",
       " ('is', 'truer'): {'than': 1},\n",
       " ('is', 'you-er'): {'than': 1},\n",
       " ('know', 'END'): {'the': 1},\n",
       " ('learn', 'the'): {'more': 1},\n",
       " ('left', 'and'): {'think': 1},\n",
       " ('low', 'and'): {'think': 1},\n",
       " ('more', 'places'): {'you’ll': 1},\n",
       " ('more', 'that'): {'you': 2},\n",
       " ('more', 'things'): {'you': 1},\n",
       " ('no', 'one'): {'alive': 1},\n",
       " ('oh', 'the'): {'thinks': 1},\n",
       " ('on', 'your'): {'own': 1},\n",
       " ('one', 'alive'): {'who': 1},\n",
       " ('only', 'you'): {'try': 1},\n",
       " ('own', 'END'): {'the': 1},\n",
       " ('places', 'you’ll'): {'go': 1},\n",
       " ('read', 'the'): {'more': 1},\n",
       " ('right', 'and'): {'think': 1},\n",
       " ('shoes', 'END'): {'you': 1},\n",
       " ('steer', 'yourself'): {'any': 1},\n",
       " ('than', 'true'): {'END': 1},\n",
       " ('than', 'you'): {'END': 1},\n",
       " ('that', 'is'): {'truer': 1},\n",
       " ('that', 'you'): {'learn': 1, 'read': 1},\n",
       " ('the', 'more'): {'places': 1, 'that': 2, 'things': 1},\n",
       " ('the', 'thinks'): {'you': 1},\n",
       " ('there', 'is'): {'no': 1},\n",
       " ('things', 'you'): {'will': 1},\n",
       " ('think', 'high'): {'END': 1},\n",
       " ('think', 'left'): {'and': 1},\n",
       " ('think', 'low'): {'and': 1},\n",
       " ('think', 'right'): {'and': 1},\n",
       " ('think', 'up'): {'if': 1},\n",
       " ('thinks', 'you'): {'can': 1},\n",
       " ('today', 'you'): {'are': 1},\n",
       " ('true', 'END'): {'there': 1},\n",
       " ('truer', 'than'): {'true': 1},\n",
       " ('up', 'if'): {'only': 1},\n",
       " ('who', 'is'): {'you-er': 1},\n",
       " ('will', 'know'): {'END': 1},\n",
       " ('you', 'END'): {'that': 1, 'you': 1},\n",
       " ('you', 'are'): {'you': 1},\n",
       " ('you', 'can'): {'steer': 1, 'think': 1},\n",
       " ('you', 'choose'): {'END': 1},\n",
       " ('you', 'have'): {'brains': 1, 'feet': 1},\n",
       " ('you', 'learn'): {'the': 1},\n",
       " ('you', 'read'): {'the': 1},\n",
       " ('you', 'try'): {'END': 1},\n",
       " ('you', 'will'): {'know': 1},\n",
       " ('you-er', 'than'): {'you': 1},\n",
       " ('your', 'head'): {'END': 1},\n",
       " ('your', 'own'): {'END': 1},\n",
       " ('your', 'shoes'): {'END': 1},\n",
       " ('yourself', 'any'): {'direction': 1},\n",
       " ('you’ll', 'go'): {'END': 1},\n",
       " ('you’re', 'on'): {'your': 1}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_higher_order_markov_model(2, frags)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
